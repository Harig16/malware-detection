import matplotlib
matplotlib.use("Agg")

from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.ticker import FuncFormatter
import numpy as np
import pandas as pd
from scipy import interp
from itertools import cycle

"""
Graph, Confustion Matrix, ROC, Classification report are generated and stored in image
"""

def cm(testX, testY, model_predict, n_classes, model_labels, model_name):
    """
    confusion matrix
    """
    model_matrix = confusion_matrix(testY.argmax(axis=1), model_predict.argmax(axis=1))
    total_samples = model_matrix.sum(axis=1)[:, np.newaxis]
    normed_conf_mat = model_matrix.astype('float') / total_samples
    model_df_cm = pd.DataFrame(normed_conf_mat, range(n_classes), range(n_classes))
    plt.figure(figsize = (20,14))
    sns.set(font_scale=1.4) #for label size
    fmt = lambda x,pos: '{:.1f}'.format(x)
    ax = sns.heatmap(model_df_cm, annot=True, annot_kws={"size": 12},
                cbar_kws={'format': FuncFormatter(fmt)}, cmap = "Greens", linewidths = 0.5, vmin=0, vmax=1, xticklabels= model_labels, yticklabels=model_labels)
    #fmt='.1f',
    cbar = ax.collections[0].colorbar
    cbar.set_ticks([0, 0.2,.75, 1])
    cbar.set_ticklabels(['85%',"90%", "95%", '100%'])# font size
    #for t in ax.texts: t.set_text(t.get_text() + " %")
    plt.xlabel('predicted label')
    plt.ylabel('true label')
    plt.title("Confusion Matrix")
    plt.savefig(model_name.split(".")[0]+"-Confusion_Matrix.png")

def graph(EPOCHS, H, model_name):
    """
    Graph Train Loss/Accuracy
    """
    plt.style.use("ggplot")
    N = EPOCHS
    plt.figure()
    plt.plot(np.arange(0, N), H.history["loss"], label="train_loss", marker = ">")
    plt.plot(np.arange(0, N), H.history["val_loss"], label="val_loss", marker = "." )
    plt.xlabel("No of Epoch")
    plt.ylabel("Loss")
    plt.legend(loc="upper left")
    plt.savefig(model_name.split(".")[0]+"-loss.png")

    plt.figure()
    plt.plot(np.arange(0, N), H.history["acc"], label="train_acc", marker = ">")
    plt.plot(np.arange(0, N), H.history["val_acc"], label="val_acc", marker = ".")
    plt.xlabel("No of Epoch")
    plt.ylabel("Accuracy")
    plt.legend(loc="upper left")
    plt.savefig(model_name.split(".")[0]+"-acc.png")

def rc(testX, testY, n_classes, model_predict, model_labels, model_name):
    """
    ROC Curve
    """
    lw = 3

    fpr = dict()
    tpr = dict()
    roc_auc = dict()
    for i in range(n_classes):
        fpr[i], tpr[i], _ = roc_curve(testY[:, i], model_predict[:, i])
        roc_auc[i] = auc(fpr[i], tpr[i])


    fpr["micro"], tpr["micro"], _ = roc_curve(testY.ravel(), model_predict.ravel())
    roc_auc["micro"] = auc(fpr["micro"], tpr["micro"])


    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))

    mean_tpr = np.zeros_like(all_fpr)
    for i in range(n_classes):
        mean_tpr += interp(all_fpr, fpr[i], tpr[i])

    mean_tpr /= n_classes

    fpr["macro"] = all_fpr
    tpr["macro"] = mean_tpr
    roc_auc["macro"] = auc(fpr["macro"], tpr["macro"])

    # Plot all ROC curves
    plt.figure(figsize=(20,20))
    plt.plot(fpr["micro"], tpr["micro"],
             label='micro-average ROC curve (area = {0:0.2f})'
                   ''.format(roc_auc["micro"]),
             color='deeppink', linestyle=':', linewidth=3)

    plt.plot(fpr["macro"], tpr["macro"],
             label='macro-average ROC curve (area = {0:0.2f})'
                   ''.format(roc_auc["macro"]),
             color='navy', linestyle=':', linewidth=3)

    colors = cycle(["b","g","r","c","m","y","k","w"])
    for i, color in zip(range(n_classes), colors):
        plt.plot(fpr[i], tpr[i], color=color, lw=lw,
                 label='ROC curve of class {0} (area = {1:0.2f})'
                 ''.format(model_labels[i], roc_auc[i]))

    plt.plot([0, 0.5], [0.90, 1.001], 'k--', lw=lw)
    plt.xlim([0, 0.5])
    plt.ylim([0.90, 1.01])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Multi-class ROC ')
    plt.legend(loc="lower right")
    plt.savefig(model_name.split(".")[0]+"-roc")

def pr(testY, model_predict):
    """
    classification report
    """
    model_predicted = np.argmax(model_predict, axis=1)
    model_report = classification_report(np.argmax(testY, axis=1), model_predicted)
    return model_report
